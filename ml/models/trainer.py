"""
Trainer –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Seq2Seq –º–æ–¥–µ–ª–∏

–ö–ª–∞—Å—Å Trainer —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è:
1. –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (forward pass)
2. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ loss
3. –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ (backpropagation)
4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
5. –í–∞–ª–∏–¥–∞—Ü–∏—è
6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time
import os
from typing import Optional, Dict

from .seq2seq import Seq2Seq
from .config import ModelConfig, TrainingConfig


class Trainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Seq2Seq –º–æ–¥–µ–ª–∏"""
    
    def __init__(
        self,
        model: Seq2Seq,
        optimizer: optim.Optimizer,
        criterion: nn.Module,
        device: str = 'cpu',
        grad_clip: float = 5.0
    ):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device
        self.grad_clip = grad_clip
        
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')
        self.patience_counter = 0
    
    def train_epoch(self, dataloader: DataLoader, teacher_forcing_ratio: float = 0.5) -> float:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–µ"""
        self.model.train()
        epoch_loss = 0
        
        for batch_idx, (questions, answers, q_lengths, a_lengths) in enumerate(dataloader):
            questions = questions.to(self.device)
            answers = answers.to(self.device)
            q_lengths = q_lengths.to(self.device)
            
            self.optimizer.zero_grad()
            
            outputs = self.model(questions, answers, q_lengths, teacher_forcing_ratio)
            
            output_dim = outputs.shape[-1]
            outputs = outputs[:, 1:].reshape(-1, output_dim)
            answers = answers[:, 1:].reshape(-1)
            
            loss = self.criterion(outputs, answers)
            loss.backward()
            
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)
            self.optimizer.step()
            
            epoch_loss += loss.item()
            
            if (batch_idx + 1) % TrainingConfig.LOG_EVERY == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                print(f"   Batch {batch_idx + 1}/{len(dataloader)} | Loss: {avg_loss:.4f}")
        
        return epoch_loss / len(dataloader)
    
    def validate(self, dataloader: DataLoader) -> float:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            dataloader: DataLoader —Å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        
        Returns:
            –°—Ä–µ–¥–Ω–∏–π loss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        self.model.eval()
        epoch_loss = 0
        
        with torch.no_grad():
            for questions, answers, q_lengths, a_lengths in dataloader:
                questions = questions.to(self.device)
                answers = answers.to(self.device)
                q_lengths = q_lengths.to(self.device)
                
                # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (–±–µ–∑ teacher forcing)
                outputs = self.model(
                    questions, 
                    answers, 
                    q_lengths,
                    teacher_forcing_ratio=0.0
                )
                
                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ loss
                output_dim = outputs.shape[-1]
                outputs = outputs[:, 1:].reshape(-1, output_dim)
                answers = answers[:, 1:].reshape(-1)
                
                loss = self.criterion(outputs, answers)
                epoch_loss += loss.item()
        
        return epoch_loss / len(dataloader)
    
    def train(
        self,
        train_loader: DataLoader,
        val_loader: Optional[DataLoader] = None,
        num_epochs: int = 10,
        teacher_forcing_ratio: float = 0.5,
        save_dir: str = None,
        early_stopping_patience: int = 3
    ):
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            train_loader: DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            val_loader: DataLoader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            num_epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            teacher_forcing_ratio: –ù–∞—á–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å teacher forcing
            save_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
            early_stopping_patience: –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è early stopping
        """
        print("\n" + "=" * 60)
        print("–ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)
        print(f"–≠–ø–æ—Ö: {num_epochs}")
        print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {self.model.count_parameters():,}")
        print("=" * 60 + "\n")
        
        for epoch in range(num_epochs):
            start_time = time.time()
            
            print(f"\n–≠–ø–æ—Ö–∞ {epoch + 1}/{num_epochs}")
            print("-" * 60)
            
            # –û–±—É—á–µ–Ω–∏–µ
            train_loss = self.train_epoch(train_loader, teacher_forcing_ratio)
            self.train_losses.append(train_loss)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if val_loader:
                val_loss = self.validate(val_loader)
                self.val_losses.append(val_loss)
                
                print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–ø–æ—Ö–∏ {epoch + 1}:")
                print(f"   Train Loss: {train_loss:.4f}")
                print(f"   Val Loss: {val_loss:.4f}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è
                if val_loss < self.best_val_loss - TrainingConfig.MIN_DELTA:
                    self.best_val_loss = val_loss
                    self.patience_counter = 0
                    print(f"   ‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å! Val Loss: {val_loss:.4f}")
                else:
                    self.patience_counter += 1
                    print(f"   ‚ö†Ô∏è –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è ({self.patience_counter}/{early_stopping_patience})")
                
                # Early stopping
                if self.patience_counter >= early_stopping_patience:
                    print(f"\n‚õî Early stopping! –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è {early_stopping_patience} —ç–ø–æ—Ö.")
                    break
            else:
                print(f"\nüìä Train Loss: {train_loss:.4f}")
            
            # –£–º–µ–Ω—å—à–∞–µ–º teacher forcing —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
            teacher_forcing_ratio *= 0.95
            
            # –í—Ä–µ–º—è —ç–ø–æ—Ö–∏
            epoch_time = time.time() - start_time
            print(f"   ‚è±Ô∏è –í—Ä–µ–º—è: {epoch_time:.2f} —Å–µ–∫")
        
        print("\n" + "=" * 60)
        print("–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print("=" * 60)
        print(f"–õ—É—á—à–∏–π Val Loss: {self.best_val_loss:.4f}")
        print("=" * 60 + "\n")


def create_trainer(model: Seq2Seq, learning_rate: float = 0.001, device: str = 'cpu') -> Trainer:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Trainer"""
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    criterion = nn.CrossEntropyLoss(ignore_index=0)
    
    trainer = Trainer(
        model=model,
        optimizer=optimizer,
        criterion=criterion,
        device=device,
        grad_clip=ModelConfig.GRAD_CLIP
    )
    
    return trainer


if __name__ == "__main__":
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ validate –∏ train
    """
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ TRAINER - validate –∏ train")
    print("=" * 60)
    
    print("‚úÖ –ú–µ—Ç–æ–¥—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã:")
    print("   - validate(): –≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏")
    print("   - train(): –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è")
    print("\nüìä –§—É–Ω–∫—Ü–∏–∏ train():")
    print("   - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ")
    print("   - –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏")
    print("   - Early stopping")
    print("   - –£–º–µ–Ω—å—à–µ–Ω–∏–µ teacher forcing")
    print("   - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞")
    
    print("\n" + "=" * 60)
    print("‚úÖ VALIDATE –ò TRAIN –ì–û–¢–û–í–´")
    print("=" * 60)
