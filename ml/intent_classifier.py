"""
–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ RuBERT
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º –≤ FAQ
"""

import logging
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, Optional
import json
from pathlib import Path

logger = logging.getLogger(__name__)


class IntentClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –±–∞–∑–µ –æ–±—É—á–µ–Ω–Ω–æ–≥–æ RuBERT
    """
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.7):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        
        Args:
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ RuBERT
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0-1)
        """
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        self._load_model()
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞"""
        try:
            logger.info(f"ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ RuBERT –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
            self.model.to(self.device)
            self.model.eval()  # –†–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            label_mapping_path = self.model_path.parent / "label_mapping.json"
            if label_mapping_path.exists():
                with open(label_mapping_path, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                    self.id2label = {int(k): v for k, v in mapping['id2label'].items()}
                    self.label2id = mapping['label2id']
            else:
                # –ë–µ—Ä—ë–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏
                self.id2label = self.model.config.id2label
                self.label2id = self.model.config.label2id
            
            logger.info(f"‚úÖ RuBERT –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            logger.info(f"   üìã –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(self.id2label)}")
            logger.info(f"   üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
            logger.info(f"   üéØ –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {self.confidence_threshold}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ RuBERT: {e}", exc_info=True)
            raise
    
    def predict(self, text: str) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            dict: {
                'category': str,           # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
                'confidence': float,       # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0-1)
                'is_confident': bool,      # –í—ã—à–µ –ª–∏ –ø–æ—Ä–æ–≥–∞
                'all_scores': dict         # –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
            }
        """
        try:
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=128
            ).to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.softmax(outputs.logits, dim=1)[0]
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å
            predicted_id = torch.argmax(probabilities).item()
            confidence = probabilities[predicted_id].item()
            predicted_category = self.id2label[predicted_id]
            
            # –í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            all_scores = {
                self.id2label[i]: probabilities[i].item()
                for i in range(len(probabilities))
            }
            
            result = {
                'category': predicted_category,
                'confidence': confidence,
                'is_confident': confidence >= self.confidence_threshold,
                'all_scores': all_scores
            }
            
            logger.debug(
                f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: '{text[:50]}...' ‚Üí {predicted_category} "
                f"({confidence*100:.1f}%)"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}", exc_info=True)
            return {
                'category': None,
                'confidence': 0.0,
                'is_confident': False,
                'all_scores': {}
            }
    
    def get_top_categories(self, text: str, top_k: int = 3) -> list:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-K –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        
        Args:
            text: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            
        Returns:
            list: [(category, confidence), ...]
        """
        prediction = self.predict(text)
        sorted_scores = sorted(
            prediction['all_scores'].items(),
            key=lambda x: x[1],
            reverse=True
        )
        return sorted_scores[:top_k]


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä (–±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞)
_classifier_instance: Optional[IntentClassifier] = None


def init_classifier(model_path: str, confidence_threshold: float = 0.7):
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    
    Args:
        model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    """
    global _classifier_instance
    
    try:
        _classifier_instance = IntentClassifier(model_path, confidence_threshold)
        logger.info("‚úÖ RuBERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RuBERT: {e}")
        logger.warning("‚ö†Ô∏è –ë–æ—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ RuBERT –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—Ç–æ–ª—å–∫–æ DeepSeek)")
        _classifier_instance = None


def get_classifier() -> Optional[IntentClassifier]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    
    Returns:
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
    """
    return _classifier_instance


def is_classifier_available() -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    
    Returns:
        True –µ—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    """
    return _classifier_instance is not None
