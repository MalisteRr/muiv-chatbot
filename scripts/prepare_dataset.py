"""
–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç FAQ –∏–∑ —Ñ–∞–π–ª–∞ faq_70_questions.json
2. –†–∞—Å—à–∏—Ä—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é (—Å–æ–∑–¥–∞–Ω–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–π –≤–æ–ø—Ä–æ—Å–æ–≤)
3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
"""

import json
import os
import sys
import random
from typing import List, Dict

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from ml.models.config import ModelConfig


def load_faq() -> List[Dict]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ FAQ –∏–∑ —Ñ–∞–π–ª–∞
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏
    """
    try:
        with open(ModelConfig.FAQ_SOURCE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ FAQ")
        return data
    except FileNotFoundError:
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {ModelConfig.FAQ_SOURCE_PATH}")
        return []


def augment_question(question: str) -> List[str]:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–π –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Args:
        question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        
    Returns:
        –°–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞—Ü–∏–π –≤–æ–ø—Ä–æ—Å–∞
    """
    variations = []
    q_lower = question.lower()
    
    # –í–∞—Ä–∏–∞—Ü–∏–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏ "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç"
    if "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç" in q_lower:
        variations.append(question.replace("–°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "–ö–∞–∫–∞—è —Ü–µ–Ω–∞"))
        variations.append(question.replace("–°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "–ö–∞–∫–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å"))
        variations.append(question.replace("—Å—Ç–æ–∏—Ç", "–±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å"))
    
    if "–∫–∞–∫–∞—è —Ü–µ–Ω–∞" in q_lower:
        variations.append(question.replace("–ö–∞–∫–∞—è —Ü–µ–Ω–∞", "–°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç"))
    
    # –í–∞—Ä–∏–∞—Ü–∏–∏ —Å "–µ—Å—Ç—å –ª–∏" / "–∏–º–µ–µ—Ç—Å—è –ª–∏"
    if "–µ—Å—Ç—å –ª–∏" in q_lower:
        variations.append(question.replace("–ï—Å—Ç—å –ª–∏", "–ò–º–µ–µ—Ç—Å—è –ª–∏"))
        variations.append(question.replace("–ï—Å—Ç—å –ª–∏", "–î–æ—Å—Ç—É–ø–Ω–æ –ª–∏"))
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∂–ª–∏–≤—ã—Ö —Ñ–æ—Ä–º
    if not q_lower.startswith(("–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ", "—Å–∫–∞–∂–∏—Ç–µ", "—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ")):
        variations.append(f"–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, {question.lower()}")
        variations.append(f"–°–∫–∞–∂–∏—Ç–µ, {question.lower()}")
        variations.append(f"–ù–µ –º–æ–≥–ª–∏ –±—ã –≤—ã —Å–∫–∞–∑–∞—Ç—å, {question.lower()}")
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞"
    if "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞" not in q_lower:
        variations.append(f"{question.rstrip('?')}, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞?")
    
    # –í–∞—Ä–∏–∞—Ü–∏–∏ –Ω–∞—á–∞–ª–∞ –≤–æ–ø—Ä–æ—Å–∞
    if q_lower.startswith("–∫–∞–∫–∏–µ"):
        variations.append(question.replace("–ö–∞–∫–∏–µ", "–ß—Ç–æ –∑–∞"))
    
    if q_lower.startswith("–∫–∞–∫"):
        variations.append(question.replace("–ö–∞–∫", "–ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º"))
    
    # –ö—Ä–∞—Ç–∫–∏–µ —Ñ–æ—Ä–º—ã
    if len(question.split()) > 5:
        # –£–±–∏—Ä–∞–µ–º –≤–≤–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞
        short = question
        for word in ["–ø–æ–∂–∞–ª—É–π—Å—Ç–∞", "—Å–∫–∞–∂–∏—Ç–µ", "–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ"]:
            short = short.replace(word + ", ", "").replace(word + " ", "")
        if short != question:
            variations.append(short)
    
    return variations


def clean_duplicates(pairs: List[Dict]) -> List[Dict]:
    """
    –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Args:
        pairs: –°–ø–∏—Å–æ–∫ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
        
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    seen_questions = set()
    unique_pairs = []
    
    for pair in pairs:
        q_normalized = pair['question'].lower().strip()
        if q_normalized not in seen_questions:
            seen_questions.add(q_normalized)
            unique_pairs.append(pair)
    
    print(f"üßπ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(pairs) - len(unique_pairs)}")
    return unique_pairs


def prepare_training_data(faq_data: List[Dict]) -> List[Dict]:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π
    
    Args:
        faq_data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ FAQ
        
    Returns:
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    training_pairs = []
    
    print("\nüîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    for idx, item in enumerate(faq_data, 1):
        question = item['question']
        answer = item['answer']
        category = item.get('category', '–û–±—â–µ–µ')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –ø–∞—Ä—É
        training_pairs.append({
            'question': question,
            'answer': answer,
            'category': category,
            'is_original': True
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏
        variations = augment_question(question)
        for variation in variations:
            training_pairs.append({
                'question': variation,
                'answer': answer,
                'category': category,
                'is_original': False
            })
        
        if idx % 10 == 0:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx}/{len(faq_data)} –≤–æ–ø—Ä–æ—Å–æ–≤...")
    
    # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    training_pairs = clean_duplicates(training_pairs)
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    random.shuffle(training_pairs)
    
    return training_pairs


def save_dataset(data: List[Dict], filepath: str):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ JSON —Ñ–∞–π–ª
    
    Args:
        data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
    """
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filepath}")


def print_statistics(data: List[Dict]):
    """
    –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É
    
    Args:
        data: –î–∞—Ç–∞—Å–µ—Ç
    """
    print("\n" + "=" * 60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 60)
    
    total = len(data)
    originals = sum(1 for item in data if item.get('is_original', False))
    augmented = total - originals
    
    print(f"üìä –í—Å–µ–≥–æ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç: {total}")
    print(f"   ‚Ä¢ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö: {originals}")
    print(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {augmented}")
    print(f"   ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: {total/originals:.1f}x")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    categories = {}
    for item in data:
        cat = item.get('category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nüìö –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
        percentage = (count / total) * 100
        print(f"   ‚Ä¢ {cat}: {count} ({percentage:.1f}%)")
    
    # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
    avg_q_len = sum(len(item['question'].split()) for item in data) / total
    avg_a_len = sum(len(item['answer'].split()) for item in data) / total
    
    print(f"\nüìè –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞:")
    print(f"   ‚Ä¢ –í–æ–ø—Ä–æ—Å: {avg_q_len:.1f} —Å–ª–æ–≤")
    print(f"   ‚Ä¢ –û—Ç–≤–µ—Ç: {avg_a_len:.1f} —Å–ª–æ–≤")
    
    print("=" * 60)


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    """
    print("\n" + "=" * 60)
    print("–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º FAQ
    faq = load_faq()
    if not faq:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å FAQ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.")
        return
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    training_data = prepare_training_data(faq)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print_statistics(training_data)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    save_dataset(training_data, ModelConfig.DATA_PATH)
    
    print(f"\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω!")
    print(f"üìÅ –§–∞–π–ª: {ModelConfig.DATA_PATH}")
    print(f"üìä –†–∞–∑–º–µ—Ä: {len(training_data)} –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç")


if __name__ == "__main__":
    main()
